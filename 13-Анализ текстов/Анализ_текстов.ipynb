{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-библиотек-и-данных\" data-toc-modified-id=\"Загрузка-библиотек-и-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка библиотек и данных</a></span></li><li><span><a href=\"#Разделение-данных-на-обучающую-и-тестовую-выборки\" data-toc-modified-id=\"Разделение-данных-на-обучающую-и-тестовую-выборки-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Разделение данных на обучающую и тестовую выборки</a></span></li><li><span><a href=\"#Очистка-и-лемматизация-текстовых-данных\" data-toc-modified-id=\"Очистка-и-лемматизация-текстовых-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Очистка и лемматизация текстовых данных</a></span></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-Логистической-регрессии\" data-toc-modified-id=\"Обучение-модели-Логистической-регрессии-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обучение модели Логистической регрессии</a></span></li><li><span><a href=\"#Обучение-модели-LGBMClassifier\" data-toc-modified-id=\"Обучение-модели-LGBMClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение модели LGBMClassifier</a></span></li></ul></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-лучшей-модели-Логистической-регрессии-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-лучшей-модели-Логистической-регрессии-на-тестовой-выборке-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Проверка лучшей модели Логистической регрессии на тестовой выборке</a></span></li><li><span><a href=\"#Проверка-лучшей-модели-на-адекватность\" data-toc-modified-id=\"Проверка-лучшей-модели-на-адекватность-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Проверка лучшей модели на адекватность</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ текстовых комментариев  для интернет-магазина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Цель проекта:**  \n",
    "Обучить модель классифицировать комментарии на позитивные и негативные.   \n",
    "В распоряжении имееется набор данных с разметкой о токсичности правок.  \n",
    "В результате построения модели необходимо достичь значения метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**План выполнения проекта:**\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Выводы по результатам работы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек и данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение глобальных констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159292.000000\n",
       "mean        0.101612\n",
       "std         0.302139\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pth1 = 'toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2,)\n",
    "else:\n",
    "    print('Что-то пошло не так')\n",
    "    \n",
    "# убираем лишний столбец, дублирующий индекс.\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#вывод параметров датасета для проверки    \n",
    "display(df.shape)\n",
    "display(df.info())\n",
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Разделение данных на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = train_test_split(df, stratify=df['toxic'], test_size=0.25, random_state=RANDOM_STATE)\n",
    "target_train, target_test = features_train['toxic'], features_test['toxic']\n",
    "features_train, features_test = features_train.drop('toxic', axis=1), features_test.drop('toxic', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка и лемматизация текстовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим  функцию для предобработки и токенизации текста на английском языке. \n",
    "Она удаляет стоп-слова, цифры и знаки пунктуации, переводит слова в нижний регистр, \n",
    "разбивает слова на токены, добавляет к ним POS-тег, лемматизирует с помощью WordNetLemmatizer.\n",
    "Если при вызове функции был передан cache, то результаты лемматизации сохраняются в кэше, \n",
    "чтобы повторная обработка одного и того же слова не требовала лишних вычислений.\n",
    "Возвращает функция список уникальных лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_tokenize_text(text, cache=None):\n",
    "    \n",
    "    # если пришло что-то не то\n",
    "    if not isinstance(text, str) or text == '':\n",
    "        return []\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # удаление цифр, пунктуации и приведение к нижнему регистру\n",
    "    text = text.translate(str.maketrans('', '', string.digits + string.punctuation)).lower()\n",
    "\n",
    "    # токенизация\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Определяем соответствие между тегами частей речи NLTK и WordNet\n",
    "    tag_map = {'N': wordnet.NOUN,\n",
    "               'V': wordnet.VERB,\n",
    "               'R': wordnet.ADV,\n",
    "               'J': wordnet.ADJ}\n",
    "    \n",
    "    # лемматизация токенов с использованием кэша и учетом post_tag\n",
    "    words_lem, added_words = [], set()\n",
    "    for token in tokens:\n",
    "        if len(token) > 1 and token not in stop_words:\n",
    "            if cache is not None and token in cache:\n",
    "                lem_token = cache[token]\n",
    "            else:\n",
    "                # Определение post_tag для слова\n",
    "                post_tag = nltk.pos_tag([token])[0][1]\n",
    "                # Приводим тег части речи к формату WordNet\n",
    "                wn_tag = tag_map.get(post_tag[0].upper(), wordnet.NOUN)\n",
    "                # Лемматизация слова с указанием post_tag\n",
    "                lem_token = lemmatizer.lemmatize(token, wn_tag)\n",
    "                if cache is not None:\n",
    "                    cache[token] = lem_token\n",
    "            # Проверяем, было ли уже добавлено такое слово\n",
    "            if lem_token not in added_words:\n",
    "                words_lem.append(lem_token)\n",
    "                added_words.add(lem_token)\n",
    "\n",
    "    return ' '.join(words_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим эту функцию к нашим данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b64f0752224b6096cbf0f5514346f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45731470f04744a5ac6135dad0d30724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 46s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cached_lemmas = {}\n",
    "\n",
    "features_train['lemm_text'] = features_train['text'].progress_apply(lambda x: preprocess_and_tokenize_text(x, cached_lemmas))\n",
    "\n",
    "features_test['lemm_text'] = features_test['text'].progress_apply(lambda x: preprocess_and_tokenize_text(x, cached_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129315</th>\n",
       "      <td>Accusation of vandalism? \\n\\nWhat was the caus...</td>\n",
       "      <td>accusation vandalism cause purpose make remove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8868</th>\n",
       "      <td>Shorter Oxford English Dictionary\\nArrived tod...</td>\n",
       "      <td>shorter oxford english dictionary arrive today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75827</th>\n",
       "      <td>Kim, stop! You are not helping here!!! This is...</td>\n",
       "      <td>kim stop help fan fire make hotter cooler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137701</th>\n",
       "      <td>My blocking by user Jayron32  \\n\\nI believe  t...</td>\n",
       "      <td>block user jayron believe whilst warrant avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28407</th>\n",
       "      <td>Simple quote\\nDon't you think this essentially...</td>\n",
       "      <td>simple quote dont think essentially kantian ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "129315  Accusation of vandalism? \\n\\nWhat was the caus...   \n",
       "8868    Shorter Oxford English Dictionary\\nArrived tod...   \n",
       "75827   Kim, stop! You are not helping here!!! This is...   \n",
       "137701  My blocking by user Jayron32  \\n\\nI believe  t...   \n",
       "28407   Simple quote\\nDon't you think this essentially...   \n",
       "\n",
       "                                                lemm_text  \n",
       "129315  accusation vandalism cause purpose make remove...  \n",
       "8868    shorter oxford english dictionary arrive today...  \n",
       "75827           kim stop help fan fire make hotter cooler  \n",
       "137701  block user jayron believe whilst warrant avoid...  \n",
       "28407   simple quote dont think essentially kantian ma...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#проверка результата\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка от нелемматизированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.drop('text', axis=1)\n",
    "features_test = features_test.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание корпусов слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = list(features_train['lemm_text'])\n",
    "corpus_test = list(features_test['lemm_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка данных методом TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "\n",
    "features_train_tfidf = vect.fit_transform(corpus_train)\n",
    "features_test_tfidf = vect.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "В процессе подготовки данных было выполнено следующее:\n",
    "- Загрузка данных\n",
    "- Разбиение выборки на тренировочную и тестовую для обучения моделей.\n",
    "- Очистка и лемматизация текстовых данных\n",
    "- Создание корпусов слов\n",
    "- Обработка данных методом TF-IDF\n",
    "\n",
    "В результате, данные полностью готовы для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем оценивать качество обучения на тренировочной выборке с применением кросс-валидации и подбором гиперпараметров для двух моделей, построенных на разных принципах: \n",
    "- модели Логистической регрессии - это линейная модель классификации\n",
    "- модели LGBMClassifier - это модель классификации на основе деревьев с применением  градиентного бустинга\n",
    "\n",
    "В результате будет выбрана лучшая модель, которая потом будет проверяться на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели Логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры лучшей модели: {'class_weight': {0: 1, 1: 4}}\n",
      "Метрика RMSE лучшей модели: 0.7824240674151615\n",
      "CPU times: total: 2 s\n",
      "Wall time: 39.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=RANDOM_STATE) \n",
    "\n",
    "# определение списка и диапазона гиперпараметров для подбора\n",
    "grid_space = [{               \n",
    "               'class_weight': [{0:1, 1:4}, {0:1, 1:6}, 'balanced', None]\n",
    "             }]\n",
    "\n",
    "# подбор параметров с кросс-валидацией\n",
    "lr_grid = GridSearchCV(model_lr, \n",
    "                       param_grid=grid_space, \n",
    "                       cv=5, \n",
    "                       scoring='f1', \n",
    "                       n_jobs=-1)\n",
    "\n",
    "model_grid_lr = lr_grid.fit(features_train_tfidf,target_train)\n",
    "\n",
    "final_score_lr = model_grid_lr.best_score_\n",
    "\n",
    "print('Гиперпараметры лучшей модели: '+str(model_grid_lr.best_params_))\n",
    "print('Метрика RMSE лучшей модели: '+str(final_score_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры лучшей модели: {'learning_rate': 0.1, 'n_estimators': 150}\n",
      "Метрика F1 лучшей модели: 0.7611583020053961\n",
      "CPU times: total: 7min 40s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgbm = LGBMClassifier(random_state=RANDOM_STATE) \n",
    "\n",
    "# определение списка и диапазона гиперпараметров для подбора\n",
    "grid_space = [{\n",
    "                'learning_rate': [0.1, 0.01],\n",
    "                'n_estimators': [50, 100, 150],\n",
    "               }]\n",
    "\n",
    "# подбор параметров с кросс-валидацией\n",
    "lgbm_boost_grid = GridSearchCV(model_lgbm, \n",
    "                               param_grid=grid_space, \n",
    "                               cv=5, \n",
    "                               scoring='f1', \n",
    "                               n_jobs=-1)\n",
    "\n",
    "model_grid_lgbm = lgbm_boost_grid.fit(features_train_tfidf,target_train)\n",
    "\n",
    "final_score_lgbm = model_grid_lgbm.best_score_\n",
    "\n",
    "print('Гиперпараметры лучшей модели: '+str(model_grid_lgbm.best_params_))\n",
    "print('Метрика F1 лучшей модели: '+str(final_score_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**  \n",
    "Обе модели при обучении показали результат выше необходимого порогового уровня F1 = 0.75  \n",
    "Наилучший результат по метрике F1 = 0.78 показала модель Логистической регрессии со следующими гиперпараметрами:  \n",
    "- class_weight = {0: 1, 1: 4}, \n",
    "\n",
    "    \n",
    "Именно эта модель признана лучшей и будет выбрана для проверки на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка лучшей модели Логистической регрессии на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 лучшей модели: 0.7933316989458201\n"
     ]
    }
   ],
   "source": [
    "predictions_test = model_grid_lr.predict(features_test_tfidf)\n",
    "print(\"Метрика F1 лучшей модели:\", f1_score(target_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "Метрика F1 = 0.79 лучшей модели на тестовой выборке даже лучше, чем при обучении и заведомо выше целевого уровня 75, следовательно модель удвлетворяет требованиям заказчика.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка лучшей модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для прверки модели на адекватность сравним её с константной моделью классификации DummyClassifier, работающей по стратегии stratified. Такая модель предсказывает значения целевой переменной с учетом распределения классов в обучающем наборе данных и случайным образом выбирает классы с вероятностями, пропорциональными их частоте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Dummy, тестовая выборка\n",
      "F1: 0.09811413780352521\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "\n",
    "# обучение модели на тренировочной выборке\n",
    "dummy_clf.fit(features_train_tfidf,target_train) \n",
    "\n",
    "# получение предсказания модели\n",
    "predictions_dummy = dummy_clf.predict(features_test_tfidf) \n",
    "\n",
    "print(\"Модель Dummy, тестовая выборка\")\n",
    "\n",
    "# определение качества модели Dummy на тестовой выборке\n",
    "print(\"F1:\", f1_score(target_test, predictions_dummy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**    \n",
    "Модель Dummy показала результат F1 = 0.10  \n",
    "Это значительно хуже, чем результат нашей лучшей модели.  \n",
    "Следовательно выбранная нами модель более, чем адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В процессе выполнения проекта было выполнено следующее:**\n",
    "\n",
    "- Загрузка данных\n",
    "- Подготовка данных для обучения моделей:\n",
    " - Разбиение выборки на тренировочную и тестовую.\n",
    " - Очистка и лемматизация текстовых данных\n",
    " - Создание корпусов слов\n",
    " - Обработка данных методом TF-IDF\n",
    "- Обучение на тренировочной выборке следующих моделей:\n",
    " - модели Логистической регрессии\n",
    " - модели градиентного бустинга LGBMClassifier\n",
    "- Тестирование лучшей модели:\n",
    " - Оценка качества предсказания на тестовой выборке мо метрике F1\n",
    " - Проверка на адекватность сравнением с DummyClassifier\n",
    " \n",
    "**Результат обучения моделей:**\n",
    " - Наивысшее качество по метрике F1 = 0.78 при обучении на тренировочной выборке показала модель Логистической регрессии с подобранными с использованием кросс-валидации гиперпараметрами, следовательно она и признана лучшей. \n",
    " - Метрика F1 = 0.79 выбранной модели на тестовой выборке даже лучше, чем при обучении и заведомо выше целевого уровня 0.75, следовательно модель  Логистической регрессии удовлетворяет требованиям заказчика.  \n",
    " - Модель Логистической регрессии прошла проверку на адекватность, показав результат по метрике F1 значительно лучше, чем константная модель классификации DummyClassifier, работающей по стратегии stratified.\n",
    " \n",
    "**Рекомендация сотрудникам интернет-магазина:**\n",
    "- Предлагается использовать разработанную в данном проекте модель Логистической регрессии с подобранными гиперпараметрами для классификации комментариев на позитивные и негативные, в рамках нового сервиса, с целью поиска токсичных комментариев и отправки их на модерацию. \n",
    "- Данная модель показала наилучший результат по метрике F1 существенно выше требуемого значения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1011.99px",
    "left": "37.983px",
    "top": "182.415px",
    "width": "302.386px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
